---
title: "Semantic_snakes"
output: html_document
date: "2023-11-21"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# INSTALL AND LOAD PACKAGES  
```{r}
library(tidyverse)
library(lme4)
```
# loading in data 
```{r}
descriptive = read.csv("sona11.28(updated).csv")%>%
  mutate(rt=as.numeric(rt), revised_correct=as.numeric(revised_correct))
```

# INSPECT DATA
```{r}
nrow(descriptive)
ncol(descriptive)
descriptive%>% pull(ID) %>% unique() %>% length()
descriptive %>% group_by(ID) %>% count()
```

Independent variables: cue (foobly, dodish, geck, mipp), type of trial (congruent vs incongruent IAT), type of word (real vs novel)
Dependent variables: correct, revised_correct, rt, AVERAGE SENTENCE SCORE

#BASIC DESCRIPTIVES 

# attention trials data frame
```{r}
attention_trials = descriptive %>%
  filter(typeoftrial == "attention")%>%
  select(ID, revised_response, novel1, novel2, novel3, revised_correct)

#mean
attention_trials %>% 
  summarize(mean_accuracy = mean(revised_correct),
            sd_accuracy = sd(revised_correct))

#summarize participant accuracy
subject_attention_accuracy = attention_trials %>%
  group_by(ID) %>%
  summarize(mean_accuracy = mean(revised_correct),
            sd_accuracy = sd(revised_correct))

# outlier: under 75% attention accuracy - not sure where to incorporate this in yet?
low_acc_IDs <- subject_attention_accuracy %>%
  filter(mean_accuracy < 0.75) %>% pull(ID)
```

# removing outliers 
```{r}
final_data = descriptive %>%
  filter(!ID %in% low_acc_IDs) 
```

#IAT accuracy by participant
```{r}

subset_data <- final_data %>%
  filter(typeoftrial %in% c("congruent_iat", "incongruent_iat")) %>%
   filter(!(typeoftrial %in% c("congruent_iat", "incongruent_iat") & rt < 200 | rt > 1500))%>%
  mutate(correct_numeric = ifelse(correct, 1, 0))

subject_accuracy_iat <- subset_data %>%
  group_by(ID) %>%
  summarise(mean_accuracy = mean(correct_numeric), sd_accuracy = sd(correct_numeric)) %>%
  ungroup() %>%
  select(ID, mean_accuracy)

# Mean accuracy for 'congruent_iat' trials
congruent_accuracy <- subset_data %>%
  filter(typeoftrial == "congruent_iat") %>%
  group_by(ID) %>%
  summarise(mean_accuracy_congruent = mean(correct_numeric)) %>%
  ungroup()

# Mean accuracy for 'incongruent_iat' trials
incongruent_accuracy <- subset_data %>%
  filter(typeoftrial == "incongruent_iat") %>%
  group_by(ID) %>%
  summarise(mean_accuracy_incongruent = mean(correct_numeric))%>%
  ungroup()

# Merge 
subject_accuracy_iat <- left_join(subject_accuracy_iat, congruent_accuracy, by = "ID")
subject_accuracy_iat <- left_join(subject_accuracy_iat, incongruent_accuracy, by = "ID")
```


# iat congruent by novel word
```{r}
iat_congruent_trials = final_data %>%
  filter(typeoftrial == "congruent_iat", cue %in% c("dodish", "foobly", "geck", "mipp"))%>%
  filter(!(typeoftrial %in% c("congruent_iat", "incongruent_iat") & rt < 200 | rt > 1500))%>%
  group_by(cue)%>%
  mutate(rt=as.numeric(rt))%>%
  summarize(mean_rt = mean(rt)) 
  
```

# iat incongruent by novel word
```{r}
iat_incongruent = final_data %>%
  filter(typeoftrial == "incongruent_iat", cue %in% c("dodish", "foobly", "geck", "mipp"))%>%
   filter(!(typeoftrial %in% c("congruent_iat", "incongruent_iat") & rt < 200 | rt > 1500))%>%
  group_by(cue)%>%
  mutate(rt=as.numeric(rt))%>%
  summarize(mean_rt = mean(rt)) 
  
```

#Bar graph for IAT 4 novel words
```{r}

combined_data <- bind_rows(
  mutate(iat_congruent_trials, trial_type = "Congruent"),
  mutate(iat_incongruent, trial_type = "Incongruent")
)

ggplot(combined_data, aes(x = cue, y = mean_rt, fill = trial_type)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Mean Reaction Time for Congruent and Incongruent Trials by Familiar Novel Word",
       x = "Cue",
       y = "Mean Reaction Time",
       fill = "Trial Type") +
  theme_minimal()

```
This bar graph reveals a consistent relationship between all four of the novel words: incongruent trials have a higher reaction time than congruent trials. This seems to suggest the participants have a positive valence associated with these learned novel words.

```{r}
novel_con = final_data %>%
  filter(typeoftrial == "congruent_iat", type_of_word %in% c("familiar novel", "unfamiliar novel"))%>%
   filter(!(typeoftrial %in% c("congruent_iat", "incongruent_iat") & rt < 200 | rt > 1500))%>%
  group_by(type_of_word)%>%
  mutate(rt=as.numeric(rt))%>%
  summarize(mean_rt = mean(rt))
```

# iat incongruent by novel word
```{r}
novel_incon = final_data %>%
  filter(typeoftrial == "incongruent_iat", type_of_word %in% c("familiar novel", "unfamiliar novel"))%>%
   filter(!(typeoftrial %in% c("congruent_iat", "incongruent_iat") & rt < 200 | rt > 1500))%>%
  group_by(type_of_word)%>%
  mutate(rt=as.numeric(rt))%>%
  summarize(mean_rt = mean(rt))
```

# Bar graph for IAT familiar vs unfamiliar novel word
```{r}

combined_data <- bind_rows(
  mutate(novel_con, trial_type = "Congruent"),
  mutate(novel_incon, trial_type = "Incongruent")
)

ggplot(combined_data, aes(x = type_of_word, y = mean_rt, fill = trial_type)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Mean Reaction Time for Type of Novel Word",
       x = "Cue",
       y = "Mean Reaction Time",
       fill = "Trial Type") +
  theme_minimal()
```
This bar graph seems to reveal that participants keep a consistent valence associated with novel words. For both familiar and unfamiliar words, they have a longer mean reaction time on the incongruent trials. This shows that although a positive valence is paired with novel words, it is not a unique learned relationship, as it is repeated with new psuedo words.

# histogram reaction times for IAT 
```{r}

library(ggplot2)

congruent_data <- subset(final_data, typeoftrial == "congruent_iat")
incongruent_data <- subset(final_data, typeoftrial == "incongruent_iat")

ggplot() +
  geom_histogram(data = congruent_data, aes(x = rt, fill = typeoftrial), 
                 binwidth = 50, color = "pink", alpha = 0.7, position = "identity") +
  geom_histogram(data = incongruent_data, aes(x = rt, fill = typeoftrial), 
                 binwidth = 50, color = "blue", alpha = 0.7, position = "identity") +
  labs(title = "Reaction Times - Congruent vs Incongruent Trials",
       x = "Reaction Time",
       y = "Frequency",
       fill = "Trial Type") +
  theme_minimal()

```
This histogram reveals that incongruent trials tend to have a longer mean reaction time than congruent trials. 



# INFERENTIAL STATISTICS 

# IAT RT inferential
```{r}
IATrt_model= lmerTest::lmer(rt ~ typeoftrial + (1 | ID),
                  data = subset_data)
summary(IATrt_model)

```

# Use in sentence inferential
```{r}
sentence_scoring = final_data %>%
  filter(typeoftrial=="use_in_sentence") %>%
  mutate(AVERAGE_SENTENCE_SCORE = as.numeric(AVERAGE_SENTENCE_SCORE))

sentence_model= lmer(AVERAGE_SENTENCE_SCORE ~ real.or.novel + (1 | ID),
                  data = sentence_scoring)
summary(sentence_model)
```

# Details of use in sentence data
```{r}
# Mean of all sentence scores
mean_sentence_score <- mean(sentence_scoring$AVERAGE_SENTENCE_SCORE, na.rm = TRUE)
print(mean_sentence_score)

# Histogram of individual scores
hist(sentence_scoring$AVERAGE_SENTENCE_SCORE, 
     main = "Histogram of Individual Sentence Scores",
     xlab = "Sentence Scores",
     ylab = "Frequency")

```
mean = 0.3677249
