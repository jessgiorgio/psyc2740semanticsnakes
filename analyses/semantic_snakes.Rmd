---
title: "Semantic_snakes"
output: html_document
date: "2023-11-21"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# INSTALL AND LOAD PACKAGES  
```{r}
library(tidyverse)
library(lme4)
```
# loading in data 
```{r}
descriptive = read.csv("UPDATEDfinaldata.csv")%>%
  mutate(rt=as.numeric(rt), revised_correct=as.numeric(revised_correct))
```

# INSPECT DATA
```{r}
nrow(descriptive)
ncol(descriptive)
descriptive%>% pull(ID) %>% unique() %>% length()
descriptive %>% group_by(ID) %>% count()
```

Independent variables: cue (foobly, dodish, geck, mipp), type of trial (congruent vs incongruent IAT), type of word (real vs novel)
Dependent variables: correct, revised_correct, rt, AVERAGE SENTENCE SCORE

#BASIC DESCRIPTIVES 

# attention trials data frame
```{r}
attention_trials = descriptive %>%
  filter(typeoftrial == "attention")%>%
  select(ID, revised_response, novel1, novel2, novel3, revised_correct)

#mean
attention_trials %>% 
  summarize(mean_accuracy = mean(revised_correct),
            sd_accuracy = sd(revised_correct))

#summarize participant accuracy
subject_attention_accuracy = attention_trials %>%
  group_by(ID) %>%
  summarize(mean_accuracy = mean(revised_correct),
            sd_accuracy = sd(revised_correct))

# outlier: under 75% attention accuracy - not sure where to incorporate this in yet?
low_acc_IDs <- subject_attention_accuracy %>%
  filter(mean_accuracy < 0.75) %>% pull(ID)
```

# removing outliers 
```{r}
final_data = descriptive %>%
  filter(!ID %in% low_acc_IDs) 
```

#IAT accuracy by participant
```{r}

subset_data <- final_data %>%
  filter(typeoftrial %in% c("congruent_iat", "incongruent_iat")) %>%
   filter(!(typeoftrial %in% c("congruent_iat", "incongruent_iat") & rt < 200 | rt > 1500))%>%
  mutate(correct_numeric = ifelse(correct, 1, 0))

subject_accuracy_iat <- subset_data %>%
  group_by(ID, condition) %>%
  summarise(mean_accuracy = mean(correct_numeric),
            sd_accuracy = sd(correct_numeric)) %>%
  ungroup() %>%
  select(ID, condition, mean_accuracy, sd_accuracy)

# Mean accuracy for 'congruent_iat' trials
congruent_accuracy <- subset_data %>%
  filter(typeoftrial == "congruent_iat") %>%
  group_by(ID) %>%
  summarise(mean_accuracy_congruent = mean(correct_numeric)) %>%
  ungroup()

# Mean accuracy for 'incongruent_iat' trials
incongruent_accuracy <- subset_data %>%
  filter(typeoftrial == "incongruent_iat") %>%
  group_by(ID) %>%
  summarise(mean_accuracy_incongruent = mean(correct_numeric))%>%
  ungroup()

# Merge 
subject_accuracy_iat <- left_join(subject_accuracy_iat, congruent_accuracy, by = "ID")
subject_accuracy_iat <- left_join(subject_accuracy_iat, incongruent_accuracy, by = "ID")
```

# helpful info
```{r}
nrow(subset_data)
ncol(subset_data)
subset_data%>% pull(ID) %>% unique() %>% length()
subset_data %>% group_by(ID) %>% count()

```

```{r}
result <- subset_data %>%
  group_by(ID, condition) %>%
  summarise(mean_accuracy = mean(correct_numeric),
            sd_accuracy = sd(correct_numeric)) %>%
  group_by(condition) %>%
  summarise(mean_accuracy = mean(mean_accuracy),
            sd_accuracy = mean(sd_accuracy))
```


#Bar graph for IAT 4 novel words 
```{r}
combined_data_1 = subset_data %>%
filter(typeoftrial %in% c("incongruent_iat", "congruent_iat"),
cue %in% c("dodish", "foobly", "geck", "mipp"))%>%
group_by(typeoftrial,cue) %>%
mutate(rt=as.numeric(rt))%>%
summarize(mean_rt = mean(rt), sd_rt = sd(rt))

fill_colors <- c("incongruent_iat" = "dodgerblue", "congruent_iat" = "tomato")
fill_labels <- c("incongruent_iat" = "Incongruent IAT", "congruent_iat" = "Congruent IAT")

ggplot(combined_data_1, aes(x = cue, y = mean_rt, fill = typeoftrial)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Mean Reaction Time by Familiar Novel Word",
       x = "Cue",
       y = "Mean Reaction Time",
       fill = "Trial Type") +
  theme_minimal()+
  geom_errorbar(aes(ymin = mean_rt-sd_rt,
                    ymax = mean_rt+sd_rt),
                width= .25,
                position = position_dodge(width=.9))+
scale_fill_manual(values = fill_colors, labels = fill_labels) +  # Set custom fill colors and labels
  theme_minimal()

```
This bar graph reveals a consistent relationship between all four of the novel words: incongruent trials have a higher reaction time than congruent trials. This seems to suggest the participants have a positive valence associated with these learned novel words.

# Bar graph for IAT familiar vs unfamiliar novel word
```{r}

combined_data_2 = subset_data %>%
filter(typeoftrial %in% c("incongruent_iat", "congruent_iat"),
type_of_word %in% c("familiar novel", "unfamiliar novel"))%>%
group_by(typeoftrial, type_of_word) %>%
mutate(rt=as.numeric(rt))%>%
summarize(mean_rt = mean(rt), sd_rt = sd(rt))

fill_colors <- c("incongruent_iat" = "dodgerblue", "congruent_iat" = "tomato")
fill_labels <- c("incongruent_iat" = "Incongruent IAT", "congruent_iat" = "Congruent IAT")

ggplot(combined_data_2, aes(x = type_of_word, y = mean_rt, fill = typeoftrial)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Mean Reaction Time by Type of Novel Word",
       x = "Cue",
       y = "Mean Reaction Time",
       fill = "Trial Type") +
  theme_minimal()+
  geom_errorbar(aes(ymin = mean_rt-sd_rt,
                    ymax = mean_rt+sd_rt),
                width= .25,
                position = position_dodge(width=.9))+
scale_fill_manual(values = fill_colors, labels = fill_labels) +  # Set custom fill colors and labels
  theme_minimal()
```
This bar graph seems to reveal that participants keep a consistent valence associated with novel words. For both familiar and unfamiliar words, they have a longer mean reaction time on the incongruent trials. This shows that although a positive valence is paired with novel words, it is not a unique learned relationship, as it is repeated with new psuedo words.

# histogram reaction times for IAT 
```{r}

library(ggplot2)

congruent_data <- subset(subset_data, typeoftrial == "congruent_iat")
incongruent_data <- subset(subset_data, typeoftrial == "incongruent_iat")

ggplot() +
  geom_histogram(data = congruent_data, aes(x = rt, fill = typeoftrial), 
                 binwidth = 50, color = "pink", alpha = 0.7, position = "identity") +
  geom_histogram(data = incongruent_data, aes(x = rt, fill = typeoftrial), 
                 binwidth = 50, color = "blue", alpha = 0.7, position = "identity") +
  labs(title = "Reaction Times - Congruent vs Incongruent Trials",
       x = "Reaction Time",
       y = "Frequency",
       fill = "Trial Type") +
  theme_minimal()

```
This histogram reveals that incongruent trials tend to have a longer mean reaction time than congruent trials. 



# INFERENTIAL STATISTICS 

# IAT RT inferential
```{r}
IATrt_model= lmerTest::lmer(rt ~ typeoftrial + (1 | ID),
                  data = subset_data)
summary(IATrt_model)

```

# Use in sentence inferential
```{r}

sentence_scoring <- final_data %>%
  filter(typeoftrial == "use_in_sentence") %>%
  mutate_at(vars(jess_sentence_score, jenn_sentence_score, dyana_sentence_score), as.numeric) %>%
  rowwise() %>%
  mutate(avg_data = mean(c(jess_sentence_score, jenn_sentence_score, dyana_sentence_score), na.rm = TRUE)) %>%
  mutate(avg_data = as.numeric(avg_data))


sentence_model= lmer(avg_data ~ real.or.novel + (1 | ID),
                  data = sentence_scoring)
summary(sentence_model)
```

# Details of use in sentence data
```{r}
# Mean of all sentence scores
mean_sentence_score <- mean(sentence_scoring$avg_data, na.rm = TRUE)
print(mean_sentence_score)

# Histogram of individual scores
hist(sentence_scoring$avg_data, 
     main = "Histogram of Individual Sentence Scores",
     xlab = "Sentence Scores",
     ylab = "Frequency")

```
mean = 0.27